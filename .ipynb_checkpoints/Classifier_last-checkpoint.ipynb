{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Vital Libraries\n",
    "\n",
    "## Staple Libraries such as NUMPY, PANDAS and MATPLOTLIB\n",
    "\n",
    "using Magic commands to enbale inline visualizations in Ipython Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries from SKLEARN for data preproccessing such as PCA and Standard Scaler\n",
    "\n",
    "We are assuming that we won't be needing Imputation for now as the data collected is relatively clean\n",
    "\n",
    "## Importing Pipeline to enable seemless preproccessing for each step\n",
    "\n",
    "We will be using piplines to create classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Metrics such as Classification Report and Confusion Matrix to give us an idea of how well our classifier is performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Data from CSV stored in DATA3.csv File in the main folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(['Applied'],axis=1).values\n",
    "y = df['Applied'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a array for target variable(Dependant) and Basic Variable(independant)\n",
    "\n",
    "### Here X is Basic variable\n",
    "### y is Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42 ,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Library for spliting the data into Test Data and Training Data\n",
    "\n",
    "### we use inbuilt function test_train_split to split the data into Test and Training Data. \n",
    "\n",
    "The data is stratified on Y meaning there is a a proportionate split of Y points with 1 and 0 as that in the whole data set. This is to prevent bias to creep in the Training or Test Data.\n",
    "\n",
    "### We have split the data into two partitions, with 20% for Test Data and the rest for Training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "steps2 = [('ss',StandardScaler()),('pca', PCA()),('GradientBoosterClassifier', GradientBoostingClassifier())]\n",
    "\n",
    "pipeline2 = Pipeline(steps2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use Gradient Boosting Classifier as one fo the Classifier Methods. \n",
    "\n",
    "Gradient Boosting Classifier is an advanced and relatively new classification method which provides a really good result.\n",
    "\n",
    "We will be using it in tandem wiht Logistic Regression Classifier.\n",
    "\n",
    "### We use a Pipeline to ensure that the following steps are followed up in the classifier:\n",
    "\n",
    "#### Standard Scalar for scaling the data into a normalized format\n",
    "#### Principal Component Analysis to ensure a better classification through changing the orientation of data\n",
    "#### Actual Classification through Gradient Boosted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = [('ss',StandardScaler()),('pca', PCA()),('logistic_regression', LogisticRegression())]\n",
    "\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We define another pipeline for Logistic Regression \n",
    "\n",
    "Logistic Regression is one of the simpler methods in Pattern Classification, and it is used extensively to as it genreally gives a good enough result. \n",
    "\n",
    "In it's own, it gives us a good score, but we try to maximize it further using ensemble method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('lr', pipeline), ('gb', pipeline2)], voting='soft')\n",
    "eclf1.fit(X_train,y_train)\n",
    "c3 = eclf1.score(X_test,y_test)\n",
    "prediction_ensemble = eclf1.predict(X_test)\n",
    "print c3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "\n",
    "## We use Ensemble method from Sklearn to enable a voting of combination of Logistical Regression Classifier and Gradient Boosting Classifier to obtain a really good score.\n",
    "\n",
    "The ensemble method used is voting Classifier, with Soft Voting Scheme. It is first intitialised with the pipelines created for both the Gradient Boosting and Logistical Regression Classifier.\n",
    "\n",
    "It is then fit to the training data.\n",
    "\n",
    "It is then compared to the test data and the we get a really awesome score of 0.8815 which means it classifies with an accuracy of 88%\n",
    "\n",
    "# Soft Voting Scheme:\n",
    "### Soft Voting Scheme predicts the class label based on the argmax of the sums of the predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.95      0.92      1472\n",
      "          1       0.84      0.68      0.75       528\n",
      "\n",
      "avg / total       0.88      0.88      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediction_ensemble))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report gives an Indepth Analysis of the precision and F1 score to enable us to understand the output and it's correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1404   68]\n",
      " [ 169  359]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,prediction_ensemble))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix gives us the prevelance of True Positive, False Positive, True Negative and False Negative to allow us to effectively gauge the effictiveness of our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ensemble_GBC_LR.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(eclf1, 'ensemble_GBC_LR.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOBLIB is used to store the classifier result, to enable us to use it at a whim in other applications by simply importing it ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.344058993707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "val = eclf1.predict_proba(X_test)\n",
    "print log_loss(y_test,val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Log Loss Metric Penalises the if the classifier predicts the class label with very high confidence.\n",
    "\n",
    "It uses the following Metric :\n",
    "\n",
    "                    -log P(yt|yp) = -(yt log(yp) + (1 - yt) log(1 - yp))\n",
    "                    \n",
    "## The Really low Log Loss score indicates that this classifier is really good at what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
